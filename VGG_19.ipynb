{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oW-sEfTyq7wZ"
   },
   "source": [
    "FULL IMPLEMENTATION OF VGG-19 NEURAL NETWORK USING TENSORFLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "IMPORT DATASET"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z5OiL6E0qC5e"
   },
   "source": [
    "IMPORT TENSORFLOW V2 - LIMITED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KBvUbXuop9H3"
   },
   "source": [
    "IMPORT NECESSARY LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1KEJtnUNhGrw"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import requests\n",
    "import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Owp-dxqBq1dJ"
   },
   "source": [
    "CONSTRUCT AN ENCODER TO CLASSIFY RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wCQPhN7kq5CA",
    "outputId": "90ee7ff2-f760-4c81-8c02-0bb8b323c8c4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = OneHotEncoder()\n",
    "encoder.fit([[0], [1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_LdDFnK3rNjm"
   },
   "source": [
    "PRE-PROCESS THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pNbWaDmyrPqe"
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "paths = []\n",
    "result = []\n",
    "\n",
    "def pre_process(position, path):\n",
    "  paths = []\n",
    "  for x, y, z in os.walk(path):\n",
    "    for file in z: paths.append(os.path.join(x, file))\n",
    "              \n",
    "  for path in paths:\n",
    "    img = Image.open(path)\n",
    "    size=(224,224)\n",
    "    img = img.resize(size)\n",
    "    img = np.array(img)\n",
    "\n",
    "    if (img.shape == (224, 224, 3)):\n",
    "        data.append(np.array(img))\n",
    "        result.append(encoder.transform([[position]]).toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xeQ2_xR2sKgN"
   },
   "source": [
    "START THE DATASET PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p8YOsZ6iremY"
   },
   "outputs": [],
   "source": [
    "pre_process(0, '/content/Dataset/Train/Beans')\n",
    "pre_process(1, '/content/Dataset/Train/Redonion')\n",
    "\n",
    "data = np.array(data)\n",
    "result = np.array(result)\n",
    "result = result.reshape(data.shape[0], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mMJ9Scwwu3f9"
   },
   "source": [
    "SPLIT THE DATA FOR BOTH TESTING AND TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "id": "Ul7JNVqdu3EV",
    "outputId": "2ff17448-5235-4732-8cc6-f96bae2fe4af"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-9-c118d60bf188>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mx_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx_test\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_test\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrain_test_split\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshuffle\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrandom_state\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_split.py\u001B[0m in \u001B[0;36mtrain_test_split\u001B[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001B[0m\n\u001B[1;32m   2418\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2419\u001B[0m     \u001B[0mn_samples\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_num_samples\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marrays\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2420\u001B[0;31m     n_train, n_test = _validate_shuffle_split(\n\u001B[0m\u001B[1;32m   2421\u001B[0m         \u001B[0mn_samples\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdefault_test_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.25\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2422\u001B[0m     )\n",
      "\u001B[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_split.py\u001B[0m in \u001B[0;36m_validate_shuffle_split\u001B[0;34m(n_samples, test_size, train_size, default_test_size)\u001B[0m\n\u001B[1;32m   2096\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2097\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mn_train\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2098\u001B[0;31m         raise ValueError(\n\u001B[0m\u001B[1;32m   2099\u001B[0m             \u001B[0;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2100\u001B[0m             \u001B[0;34m\"resulting train set will be empty. Adjust any of the \"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data, result, test_size=0.2, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NvJ2HEgGp1Lg"
   },
   "source": [
    "CREATE VGG-19 MODEL USING SEQUENTIAL API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5lA_IMsnhMpa"
   },
   "outputs": [],
   "source": [
    "def createModel(inputShape=(224, 224, 3)):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, kernel_size=(3,3), padding= 'same', activation= 'relu', input_shape= inputShape))\n",
    "    model.add(Conv2D(64, kernel_size=(3,3), padding= 'same', activation= 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides= (2,2)))\n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=(3,3), padding= 'same', activation= 'relu'))\n",
    "    model.add(Conv2D(128, kernel_size=(3,3), padding= 'same', activation= 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides= (2,2)))\n",
    "\n",
    "    model.add(Conv2D(256, kernel_size=(3,3), padding= 'same', activation= 'relu'))\n",
    "    model.add(Conv2D(256, kernel_size=(3,3), padding= 'same', activation= 'relu'))\n",
    "    model.add(Conv2D(256, kernel_size=(3,3), padding= 'same', activation= 'relu'))\n",
    "    model.add(Conv2D(256, kernel_size=(3,3), padding= 'same', activation= 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides= (2,2)))\n",
    "\n",
    "    model.add(Conv2D(512, kernel_size=(3,3), padding= 'same', activation= 'relu'))\n",
    "    model.add(Conv2D(512, kernel_size=(3,3), padding= 'same', activation= 'relu'))\n",
    "    model.add(Conv2D(512, kernel_size=(3,3), padding= 'same', activation= 'relu'))\n",
    "    model.add(Conv2D(512, kernel_size=(3,3), padding= 'same', activation= 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides= (2,2)))\n",
    "\n",
    "    model.add(Conv2D(512, kernel_size=(3,3), padding= 'same', activation= 'relu'))\n",
    "    model.add(Conv2D(512, kernel_size=(3,3), padding= 'same', activation= 'relu'))\n",
    "    model.add(Conv2D(512, kernel_size=(3,3), padding= 'same', activation= 'relu'))\n",
    "    model.add(Conv2D(512, kernel_size=(3,3), padding= 'same', activation= 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides= (2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation= 'relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(4096, activation= 'relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(6, activation= 'softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "agNVsTaSqKOn"
   },
   "source": [
    "COMPILE THE NEURAL NETWORK MODEL WITH LEARNING RATE OF 0.001 OF Adamax OPTIMISER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lv1tE4MXi66v"
   },
   "outputs": [],
   "source": [
    "model = createModel()\n",
    "model.compile(optimizer= tf.keras.optimizers.Adamax(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TtDc02DIvPpj"
   },
   "source": [
    "START TRAINING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IGbjQEq0vSYV"
   },
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs = 10, batch_size = 16, verbose = 1,validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w9ChVltp38BO"
   },
   "source": [
    "EVALUATE THE LOSS & ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hXaWASudV4wY"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Test', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uI9ROkwb4KM6"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Test', 'Validation'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MkMPnZ2H4RAd"
   },
   "source": [
    "MODEL TESTING AND EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ne_razUx4YXm"
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "def names(number):\n",
    "  return 'Beans' if number==0.0 else 'Red Onion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6j9iqQJ84VH1"
   },
   "outputs": [],
   "source": [
    "# TEST BEANS\n",
    "img = Image.open('/content/Dataset/Test/Beans/frame10.jpg')\n",
    "x = np.array(img.resize((224,224)))\n",
    "x = x.reshape(1,224,224,3)\n",
    "res = model.predict_on_batch(x)\n",
    "classification = np.where(res == np.amax(res))[1][0]\n",
    "imshow(img)\n",
    "print('Confidence score:', str(res[0][classification]*100) + '%')\n",
    "print('Result:', names(classification))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wlk_RQkH5kAO"
   },
   "outputs": [],
   "source": [
    "# TEST RED ONION\n",
    "img = Image.open('/content/Dataset/Test/Redonion/frame100.jpg')\n",
    "x = np.array(img.resize((224,224)))\n",
    "x = x.reshape(1,224,224,3)\n",
    "res = model.predict_on_batch(x)\n",
    "classification = np.where(res == np.amax(res))[1][0]\n",
    "imshow(img)\n",
    "print('Confidence score:', str(res[0][classification]*100) + '%')\n",
    "print('Result:', names(classification))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bZuTGEuT4uFf"
   },
   "source": [
    "DICE COEFFICIENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VkOELEWq4wbm"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report, accuracy_score, precision_recall_curve, average_precision_score, plot_precision_recall_curve, f1_score\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "p_y = model.predict(x_test, verbose=False)\n",
    "fpr, tpr, th = roc_curve(y_test.argmax(axis=1), p_y.argmax(axis=1), pos_label=1)\n",
    "fig, c_ax = plt.subplots(1,1, figsize=(9, 9))\n",
    "c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % ('Classification', auc(fpr, tpr)))\n",
    "c_ax.plot([0,1], [0,1], color='red', lw=1, linestyle='--')\n",
    "c_ax.legend()\n",
    "c_ax.set_xlabel('False Positive Rate')\n",
    "c_ax.set_ylabel('True Positive Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pcNyYsn044H0"
   },
   "source": [
    "PRECISION AND RECALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wc68YLZa4thj"
   },
   "outputs": [],
   "source": [
    "p_y = model.predict(x_test, verbose=False)\n",
    "fig, c_ax = plt.subplots(1,1, figsize=(9, 9))\n",
    "p, r, th = precision_recall_curve(y_test.argmax(axis=1), p_y.argmax(axis=1), pos_label=1)\n",
    "aps = average_precision_score(y_test, p_y)\n",
    "c_ax.plot(r, p, label = '%s (AP Score:%0.2f)'  % ('Classification', aps))\n",
    "c_ax.plot(r, p, color='navy', lw=2)\n",
    "c_ax.legend()\n",
    "c_ax.set_xlabel('Recall')\n",
    "c_ax.set_ylabel('Precision')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jnA_iPQM5GQ-"
   },
   "source": [
    "MODEL ARCHITECTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EP-KM5MA5Ide"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import model_to_dot\n",
    "from IPython.display import SVG\n",
    "import pydot\n",
    "import graphviz\n",
    "\n",
    "SVG(model_to_dot(model, show_shapes=True, show_layer_names=True, rankdir='TB',expand_nested=False, dpi=60, subgraph=False).create(prog='dot',format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0fzSPJ9tBkXz"
   },
   "source": [
    "SAVE THE MACHINE LEARNING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "blLd7upcBUOJ"
   },
   "outputs": [],
   "source": [
    "model.save(\"/content/model_vgg_19.h5\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "32c40bccb3e0229591b1de00d63df3a651c7b5dfd3b0cbbba8a5ddb6f4340a52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
